{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6454630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=\"training_file.json\")\n",
    "\n",
    "def install_dependencies():\n",
    "    subprocess.run([\"pip\", \"install\", \"-r\", \"requirements.txt\"])\n",
    "\n",
    "def create_cluster():\n",
    "    subprocess.run([\"kind\", \"create\", \"cluster\", \"--name\", \"llm-cluster\"])\n",
    "\n",
    "def deploy_llms():\n",
    "    subprocess.run([\"kubectl\", \"apply\", \"-f\", \"llm-enterprise-deployment.yaml\"])\n",
    "    subprocess.run([\"kubectl\", \"apply\", \"-f\", \"llm-windows-deployment.yaml\"])\n",
    "\n",
    "def train_model(training_file):\n",
    "    # Placeholder: integrate with Hugging Face `transformers` or `trl`\n",
    "    print(f\"Training model with {training_file}...\")\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--mode\", choices=[\"train\", \"deploy\"], required=True)\n",
    "    parser.add_argument(\"--file\", help=\"Training file for LLM\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    install_dependencies()\n",
    "    create_cluster()\n",
    "\n",
    "    if args.mode == \"train\":\n",
    "        if args.file:\n",
    "            train_model(args.file)\n",
    "        else:\n",
    "            print(\"Training file required for training mode.\")\n",
    "    elif args.mode == \"deploy\":\n",
    "        deploy_llms()\n",
    "        print(\"LLMs deployed. Access via http://localhost:9080\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
